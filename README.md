# Step towards AI Physicist
In this repository, I haven undertaken a baby step towards creating a language model which can process and generalize semantic structures and tokens that are correlated through mathematical and physical reasoning models, in addition to usual natural language structures, as would be required for an AI model equipped with chain-of-thoughts similar to human physicists. 

As a first step, I want to emphasize the importance of creating clean data for fine-tuning such models. Without high quality data, these models would not safely learn logical reasoning in terms of semantic structures and token embeddings. So far, I have a baby model for that, which still highlights how human thinking and science writing shows up as high-dimensional correlations between lingusitic token and mathematical symobls. In order to equip any (small, large etc) language models with foolproof logical reasoning and generalization of that ability, e.g. in-context-learning, we need to better understand how to map such correlations between natural language and mathematical symobl parts of scientific papers to multi-dimensional manifolds. Here, I have limited the scope of this data model to physics papers alone, i.e. within the scope of greek symbols and LateX formatting. However, the scope of this model can be asily generalized to other fields. I have demonstrated the efficiency of this model in case of a simple 7-page long recent physics paper. However, there are still bugs that degrade the quality of the data and correlations among symbols and letters. In a future iteration, I will attempt to fix as many bug as possible. 

In case of perfect data generated from any scientific paper, and sufficiently large number of papers and compute power, state-of-the-art langauge models should develop some level of in-context-learning (ICL) ability to decipher home humans think science i.e. how mathematical symbols get correlated in accordance with scientifc concepts, and breakdown of such conecepts into logical flow among different parts of each paragarph within a page. That would be the most ideal scenario. 
